# Paper Notes

Each heading is a date, displayed in YYMM format.

Each bulletpoint is a paper, with a link to the summary written in markdown. Each bulletpoint has an indented point with some "tags" for easy searching with ctrl+f. All tags use hyphens instead of spaces. Order of tags is irrelevant.

## 2001

- [Discounted Reinforcement Learning is Not an Optimization Problem (2019) - Naik, Shariff, Yasui, Sutton](notes/discounted-rl-not-optimization-problem.md)
  - rl, optimization

## 1912

- [Training Agents using Upside-Down Reinforcement Learning (2019) - Srivastava, Shyam, Mutz, Ja≈õkowski, Schmidhuber](notes/training-agents-using-udrl.md)
  - rl, udrl, doom, a2c, dqn

## 1911

- [Contextual Word Representations: A Contextual Introduction (2019) - Smith](notes/contextual-word-representations.md)
  - nlp, embeddings, fine-tuning, transfer-learning

- [Attention is All You Need (2017) - Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, Polosukhin](notes/attention-is-all-you-need.md)
  - transformer, nlp, nmt, translation, attention

- [Universal Language Model Fine-tuning for Text Classification (2019) - Howard, Ruder](notes/universal-language-model-fine-tuning.md)
  - nlp, fine-tuning, lm, transfer-learning, embeddings 

- [The Measure of Intelligence (2019) - Chollet](notes/measure-of-intelligence.md)
  - rl, agi

- [Deep Contextualized Word Representations (2019) - Peters, Neumann, Iyyer, Gardner, Clark, Lee, Zettlemoyer](notes/deep-contextualized-word-representations.md)
  - lm, emlo, nlp, fine-tuning, transfer-learning, embeddings

## 1905

- [Towards Interpretable Reinforcement Learning Using Attention Augmented Agents (2019) - Mott, Zoran, Chrzanowski, Wierstra, Rezende](notes/towards-interpretable-rl-agents.md)
  - rl, attention, atari, interpretable-models

- [The Consciousness Prior (2017) - Bengio](notes/the-consciousness-prior.md)
  - thought, rl, vae, gan, unsupervised

- [Reinforcement Learning, Fast and Slow (2019) - Botvinick, Ritter, Wang, Kurth-Nelson, Blundell, Hassabis](notes/rl-fast-and-slow.md)
  - rl, replay-memory, biological

- [Value Iteration Networks (2016) - Tamar, Wu, Thomas, Levine, Abbeel](notes/value-iteration-networks.md)
  - rl, trpo, planning, maze

- [Trust Region Policy Optimization (2015) - Schulman, Levine, Moritz, Jordan, Abbeel](notes/trust-region-policy-optimization.md)
  - rl, atari, trpo, policy-gradient, optimization

## 1904

- [Prioritized Experience Replay (2016) - Schal, Quan, Antonoglou, Silver](notes/prioritized-experience-replay.md)
  - rl, dqn, atari, replay-memory

- [Human-level Control Through Deep Reinforcement Learning (2015) - Mnih et al.](notes/human-level-control-through-drl.md)
  - rl, dqn, atari, replay-memory

- [Gated Path Planning Networks (2018) - Lee, Parisotto, Chaplot, Xing, Salakhutdinov](notes/gated-path-planning-networks.md)
  - rl, maze, doom, planning

- [Active Neural Localization (2018) - Chaplot, Parisotto, Salakhutdinov](notes/active-neural-localization.md)
  - rl, maze, doom, a3c, localization

- [Gated-Attention Architectures for Task-Oriented Language Grounding (2017) - Chaplot, Sathyendra, Pasumarthi, Rajagopal, Salakhutdinov](notes/gated-attention-architectures.md)
  - rl, doom, rl-text, a3c

- [A Brief Survey of Deep Reinforcement Learning (2017) - Arulkumaran, Deisenroth, Brundage, Bharath](notes/a-brief-survey-of-drl.md)
  - rl, introduction, survey

- [Style-Analyzer: Fixing Code Style Inconsistencies with Interpretable Unsupervised Algorithms (2019) - Markovtsev, Long, Mougard, Slavnov, Bulychev](notes/style-analyzer.md)
  - ml, decision-tree, ml4code

- [Reinforcement Learning with Attention that Works (2019) - Manchin, Abbasnejad, va den Hengel](notes/rl-with-attention.md)
  - rl, atari, attention, ppo

- [World Models (2018) - Ha, Schmidhuber](notes/world-models.md)
  - rl, vae, evolutionary-algorithms, world-models

## 1903

- [To Tune or Not to Tune? Adapting Pretrained Representations to Diverse Tasks (2019) - Peters, Ruder, Smith](notes/to-tune-or-not-to-tune.md)
  - nlp, nli, sts, fine-tuning, transfer-learning, elmo, bert

- [Playing Atari with Six Neurons (2019) - Cuccu, Togelius, Cudre-Mauroux](notes/playing-atari-with-six-neurons.md)
  - rl, atari, neuroevolution, evolutionary-algorithms

- [Maybe Deep Neural Networks are the Best Choice for Modeling Source Code (2019) - Karamptatsis, Sutton](notes/dnns-modeling-source-code.md)
  - lm, ml4code